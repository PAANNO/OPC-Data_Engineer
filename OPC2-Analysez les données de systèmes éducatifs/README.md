# OPC2 â€“ Analysez les donnÃ©es de systÃ¨mes Ã©ducatifs

DÃ©pÃ´t de travail pour le **projet 2** du parcours **Data Engineer â€“ OpenClassrooms**.

Ce projet a une durÃ©e estimÃ©e de **30 heures** et a pour objectif de renforcer mes fondamentaux de **Python pour la Data Science** en analysant des **donnÃ©es de systÃ¨mes Ã©ducatifs** Ã  lâ€™aide de **notebooks Jupyter**.

## ğŸ¯ Objectifs du projet

RÃ©sumÃ© en quelques lignes :

- Analyser un jeu de donnÃ©es issu de systÃ¨mes Ã©ducatifs Ã  lâ€™aide de Python et de Jupyter Notebook.
- RÃ©aliser une **analyse exploratoire univariÃ©e** et des **visualisations** pour mieux comprendre les donnÃ©es.
- Mettre en place un environnement de travail adaptÃ© (Poetry / environnement virtuel, Jupyter, organisation du dÃ©pÃ´t).
- Produire des notebooks propres et structurÃ©s, pouvant Ãªtre compris par un public mÃ©tier et technique.

## ğŸ§© Contexte

- **Contexte mÃ©tier :** le projet sâ€™inscrit dans lâ€™analyse de donnÃ©es de systÃ¨mes Ã©ducatifs (indicateurs de performance, rÃ©ussite, etc.) afin de mieux comprendre ces systÃ¨mes et de prÃ©parer des analyses plus avancÃ©es.
- **Contexte technique :** jeu de donnÃ©es tabulaire (fichiers CSV) analysÃ© dans des notebooks Jupyter, en utilisant principalement **Python**, **Pandas** et des bibliothÃ¨ques de visualisation (Matplotlib / Seaborn, etc).
- **Cadre OpenClassrooms :**
  - Parcours : *Data Engineer â€“ OpenClassrooms*
  - Projet 2 : *Analysez les donnÃ©es de systÃ¨mes Ã©ducatifs*
  - DurÃ©e indicative : *30 heures*

## ğŸ“ CompÃ©tences Ã©valuÃ©es (brief OC)

CompÃ©tences cibles du projet :

- Appliquer des analyses statistiques descriptives et naviguer visuellement dans les donnÃ©es.
- Configurer lâ€™environnement de travail nÃ©cessaire Ã  lâ€™exploitation des donnÃ©es.
- Corriger les anomalies manuellement et Ã  lâ€™aide d'outils adaptÃ©s.

## ğŸ—ï¸ Architecture du projet

Grandes briques prÃ©vues pour ce projet :

- **Sources de donnÃ©es :**
  - Fichiers CSV fournis par OpenClassrooms (donnÃ©es de systÃ¨mes Ã©ducatifs).
- **Ã‰tapes du travail :**
  - Mise en place de lâ€™environnement Python / Jupyter.
  - Analyse exploratoire univariÃ©e (statistiques descriptives, visualisations).
  - Nettoyage des donnÃ©es (gestion des valeurs manquantes, incohÃ©rences, doublons, etc.).
  - Analyse plus approfondie et rÃ©ponse Ã  une problÃ©matique mÃ©tier.
- **Stockage :**
  - DonnÃ©es stockÃ©es localement dans le dossier `data/` (brut vs nettoyÃ©).
- **Outils utilisÃ©s :**
  - Python, Jupyter Notebook, Pandas, NumPy, Matplotlib, Seaborn.

Un schÃ©ma plus dÃ©taillÃ© pourra Ãªtre ajoutÃ© dans `docs/` et rÃ©fÃ©rencÃ© ici :

```mermaid
flowchart LR
    A["Jeu de donnÃ©es systÃ¨mes Ã©ducatifs (CSV)"] --> B[Exploration & statistiques descriptives]
    B --> C[Nettoyage / prÃ©paration des donnÃ©es]
    C --> D[Jeu de donnÃ©es nettoyÃ©]
    D --> E[Analyses complÃ©mentaires & visualisations]
    E --> F["Restitution (notebook / rapport)"]
```

## ğŸ› ï¸ Stack technique

- Langage : Python 3.14
- Environnement de dÃ©veloppement : VS Code + extensions (Python, Jupyter, etc.)
- GGestion de version : Git & GitHub
- Base(s) de donnÃ©es : `fichiers CSV locaux.`
- Traitements de donnÃ©es : `Pandas, NumPy`
- visualisation : `Pandas Profiling, Matplotlib, Seaborn`
- Orchestration / ingestion : `notebooks Jupyter et scripts Python`

## ğŸ“‚ Structure du dÃ©pÃ´t

```txt
.
â”œâ”€ .vscode/
â”‚  â””â”€ settings.json
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”œâ”€ processed/  # donnÃ©es nettoyÃ©es / transformÃ©es
â”œâ”€ docs/          # schÃ©mas, compte-rendus, notes, exports de diagrammes
|  â”œâ”€ Livrables/
â”œâ”€ notebooks/     # notebooks Jupyter d'exploration / POC
â”œâ”€ src/
â”‚      â”œâ”€ __init__.py
â”‚      â”œâ”€ config/        # fichiers de config (YAML/JSON)
â”‚      â””â”€ pipelines/     # scripts ETL, jobs, traitements
â”œâ”€ tests/         # tests unitaires / dâ€™intÃ©gration
â”œâ”€ .gitignore
â”œâ”€ README.md
â”œâ”€ requirements.txt
â””â”€ LICENSE        # optionnel (MIT par ex.)
```

## ğŸš€ Installation & exÃ©cution

### 1. PrÃ©requis

- Python 3.14
- Git installÃ©

### 2. Cloner le dÃ©pÃ´t
Cloner le dÃ©pÃ´t principal, puis se placer dans le dossier du projet 2 :
```bash
git clone https://github.com/PAANNO/OPC-Data_Engineer.git
cd OPC-Data_Engineer/"OPC2-Analysez les donnÃ©es de systÃ¨mes Ã©ducatifs"
```
### 3. CrÃ©er et activer l'environnement virtuel
```bash
python -m venv .venv

# Windows (PowerShell)
.\.venv\Scripts\Activate.ps1

#macOS / Linux
source .venv/bin/activate
```
### 4. Installer les dÃ©pendances
```bash
pip install --upgrade pip
pip install -r requirements.txt
```
## âœ… QualitÃ©, formatage & tests

### Formatage

Le projet utilise Black pour formater le code :

```bash
black src tests
```
### Tests

Les tests sont basÃ©s sur `pytest` :
```bash
pytest
```
## ğŸ“ Livrables OpenClassrooms
- Code source dans ce dÃ©pÃ´t Git
- Rapport / prÃ©sentation : voir dossier docs/
- (Selon le projet) exports de donnÃ©es, captures dâ€™Ã©cran, schÃ©mas dâ€™architecture

## âœï¸ Auteur
- Nom : Paul-Alexandre ANNONAY
- Parcours : Data Engineer â€“ OpenClassrooms
- Email : pa.annonay@gmail.com

### b) `.gitignore` (Python + notebooks)

```gitignore
# Environnements virtuels
.venv/
env/
venv/

# Python
__pycache__/
*.py[cod]
*.pyo
*.pyd
*.pdb

# Jupyter
.ipynb_checkpoints/

# DonnÃ©es volumineuses / temporaires
data/raw/
data/processed/
data/external/

# Logs / sorties
logs/
*.log

# OS
.DS_Store
Thumbs.db

# VS Code
.vscode/*
!.vscode/settings.json
```

### c) `requirements.txt` â€“ base pour un projet data engineer
```txt
# Core
python-dotenv

# Data manipulation
pandas
numpy

# BDD / SQL
sqlalchemy
psycopg2-binary  # si tu utilises PostgreSQL

# Notebooks
jupyter
ipykernel

# QualitÃ©
black
pytest

# Ã€ complÃ©ter selon le projet :
# pyspark
# kafka-python
# requests
# pydantic
```

### d) `.vscode/settings.json` â€“ pour que VS Code soit nickel
```json
{
  // InterprÃ©teur Python : le .venv du projet
  "python.defaultInterpreterPath": "${workspaceFolder}/.venv/bin/python",

  // Formatage automatique
  "editor.formatOnSave": true,
  "[python]": {
    "editor.defaultFormatter": "ms-python.black-formatter"
  },

  // Masquer certains dossiers dans l'explorateur
  "files.exclude": {
    "**/__pycache__": true,
    "**/.pytest_cache": true
  },

  // Jupyter: utiliser le kernel associÃ© Ã  l'interprÃ©teur sÃ©lectionnÃ©
  "jupyter.jupyterServerType": "local"
}
```